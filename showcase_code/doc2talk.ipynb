{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from moviepy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from moviepy) (2.32.3)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (70.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl (22.6 MB)\n",
      "   ---------------------------------------- 0.0/22.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.9/22.6 MB 21.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 6.6/22.6 MB 21.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 10.5/22.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 13.4/22.6 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 16.3/22.6 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 18.6/22.6 MB 15.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.2/22.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.5/22.6 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 22.6/22.6 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py): started\n",
      "  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110766 sha256=87b0b25a4a3c95942630fb572842533ba72b0e7b77bda1c5c98b3a2ba2f5ac94\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\df\\ba\\4b\\0917fc0c8833c8ba7016565fc975b74c67bc8610806e930272\n",
      "Successfully built moviepy\n",
      "Installing collected packages: imageio_ffmpeg, imageio, decorator, proglog, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 imageio-2.35.1 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from moviepy.editor import VideoFileClip\n",
    "def extract_audio_from_video(video_path, audio_output_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_output_path)\n",
    "def transcribe_audio_with_whisper(audio_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result['text']\n",
    "video_path = \"your_video_file.mp4\"  # Replace with your video file path\n",
    "audio_output_path = \"output_audio.mp3\"\n",
    "extract_audio_from_video(video_path, audio_output_path)\n",
    "transcribed_text = transcribe_audio_with_whisper(audio_output_path)\n",
    "print(transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed. The output has been saved to C:/Users/admin/Downloads/output_transcription.txt\n",
      " First things first I'm gonna say all the words inside my head I'm fired up and tired of the way the things are been oh The way the things are been oh Second things, second don't you tell me what you think that I can be I'm the one at the sale, I'm the master of my CEO The master of my CEO I was broken from a young age check my soul Into the masses, riding my poems for the few They look at me, took the mission, came here, let me sing them from heartache From the brain, taking my message, from the veins, speaking my lesson From the brain, seeing the beauty through the Hey, let me out, you let me out, believe her Believe her Hey, let me out, you let me out, believe her Believe her Hey, let the bullets fly, let the rain My love, my love, my time again Hey, let me out, you let me out, believe her Believe her Third things, turns and the prayer to the ones up above All the hate that you've heard has turned your spirit to a devil Ooh, your spirit up above Ooh, ooh I was choking in the ground, building my rain up And the clown falling like ashes to the ground Hoping my feelings, they were drowned But they never did, they were living Deppin' and flowing in here, they did, living Did you let broke up and then rain down You rain down, light Hey, let me out, you let me out, believe her Believe her Hey, let me out, you let me out, believe her Believe her Hey, let the bullets fly, let the rain My love, my love, my time again Hey, let me out, you let me out, believe her Believe her Last days, last but the grace of the fire and the flames You're the face of the future, the blood in my veins Ooh, the blood in my veins Ooh, ooh But they never did, definitely, deppin' and flowing And here, they did, living Did you let broke up and then rain down You rain down, light Hey, let me out, you let me out, believe her Believe her Hey, let the bullets fly, let the rain Hey, let me out, you let me out, believe her Believe her Hey, let the bullets fly, let the rain My love, my love, my time again Hey, let me out, you let me out, believe her Believe her\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "def transcribe_audio_with_whisper(audio_path, output_file_path):\n",
    "    # Load the Whisper model\n",
    "    model = whisper.load_model(\"base\")\n",
    "\n",
    "    # Transcribe the audio\n",
    "    result = model.transcribe(audio_path)\n",
    "    \n",
    "    # Get the transcribed text\n",
    "    transcribed_text = result['text']\n",
    "    \n",
    "    # Save the transcribed text to a file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(transcribed_text)\n",
    "    \n",
    "    print(f\"Transcription completed. The output has been saved to {output_file_path}\")\n",
    "    \n",
    "    return transcribed_text\n",
    "\n",
    "# Example usage\n",
    "audio_path = \"C:/Users/admin/Downloads/Believer(PagalNew.Com.Se).mp3\"\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = \"C:/Users/admin/Downloads/output_transcription.txt\"  # Change this to where you want to save the text\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Transcribe the audio and save to a file\n",
    "transcribed_text = transcribe_audio_with_whisper(audio_path, output_file_path)\n",
    "print(transcribed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0873f17ac4a04697bae7508d745ad515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/5.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--stabilityai--stablelm-zephyr-3b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b01d29821044ad8f4fad6cf00a1d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc5087ef16e4489978157e85d950ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8ce2ab6bf64da3b763d28b81821216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3582d59d9eab45c9a50f8171f5258698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe816e79d654e8a8c143fa45124504e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the main theme of the song?\n",
      "\n",
      "The main theme of the song is the speaker's infatuation and desperation to be with someone they perceive as special, despite the uncertainties and complexities of their relationship.\n",
      "\n",
      "The song's lyrics revolve around the idea of the speaker trying to connect with this special person, expressing their feelings through a series of poetic and romantic phrases. The speaker seems to be deeply in love with this person, but at the same time, they acknowledge the challenges and complexities of their relationship.\n",
      "\n",
      "The song's theme is further emphasized by the use of metaphors and imagery, such as the water and the ship, which symbolize the emotional turmoil and uncertainty that the speaker feels. The phrase \"Every bit in switch was a work of art\" highlights\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def query_llm(transcription_text, question):\n",
    "    # Load pre-trained model and tokenizer\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-zephyr-3b\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-zephyr-3b\")\n",
    "    \n",
    "    # Prepare the input text\n",
    "    input_text = f\"Here is the transcription of the song:\\n\\n{transcription_text}\\n\\nQuestion: {question}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    \n",
    "    # Generate response\n",
    "    outputs = model.generate(inputs['input_ids'], max_new_tokens=150, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract the answer from the response\n",
    "    return response.split(\"Question:\")[1].strip() if \"Question:\" in response else response.strip()\n",
    "\n",
    "# Load transcription data from file\n",
    "def load_transcription(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "transcription_file_path = \"C:/Users/admin/Downloads/output_transcription.txt\"  # Replace with your transcription file path\n",
    "transcription_text = load_transcription(transcription_file_path)\n",
    "\n",
    "# Ask a question about the song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the main theme of the song?\n",
      "\n",
      "Answer: The main theme of the song is overcoming obstacles and believing in oneself, expressing one's thoughts and feelings through poetry, and finding hope and inspiration in the face of adversity.\n",
      "\n",
      "Explanation: The song discusses the importance of self-belief and determination, as well as the power of expressing one's thoughts and emotions through poetry.\n",
      "\n",
      "It also touches upon the challenges faced by individuals who are often overlooked or undervalued, and the message of finding hope and inspiration in the face of adversity. The recurring theme of \"let me out\" emphasizes the need for individuals to be heard and recognized for their talents and contributions. Overall, the song's main theme is about perseverance, self-expression, and finding\n"
     ]
    }
   ],
   "source": [
    "def load_transcription(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "transcription_file_path = \"C:/Users/admin/Downloads/output_transcription.txt\"  # Replace with your transcription file path\n",
    "transcription_text = load_transcription(transcription_file_path)\n",
    "question = input()\n",
    "\n",
    "# Query the LLM and print the answer\n",
    "answer = query_llm(transcription_text, question)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
